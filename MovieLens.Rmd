---
title: "Movie recommendation using the MovieLens dataset"
output: pdf_document
author: "Felipe Urrego"
date: "02/03/2019"
---



# Introduction


 - What is Machine Learning?

In simple words, we can say that it is just a problem of approximation of a function or a relationship with the purpose to obtain new information. It can be any function of any complexity. It can even do not exist, in this case, we assume that there is a kind of law of nature or a relationship that we want to approximate.


 - Notations

We note this function $f(x)$ and its values $y=f(x)$ (or $y=f(x) + \epsilon$ where $\epsilon$ is random). Conventions for $x$ and $y$ depend on the field of science - Machine Learning or Statistical Learning - they are a bit different.

x / Features / Independent Variables (it's not the case for the raw data, but we should treat it in order to get only independent variables, for example, with help of PCA - Principal Component Analysis).
y / Label / Dependent Variable.


x can be a vector (vector of features), its length is the number of independent variables.
y is usually a scalar value.

Observation is one couple $\{x,y\}$ or just one $x$.

There are different types of Machine Learning problems, but we now consider Supervised Learning problem, it is when we have labels as described.


 - Problem formulation
 
  We have two sets of data, one is labelled (it has $x$ and $y$ and called 'train/training set') and another not (it has only $x$ and called 'test set'). Train set is $\{x_i,y_i\}_{i=0,1..n}$, where $n$ is the number of observations (they ideally should be independent).

  The objective is to get $y$ for the test set (we say to predict or to forecast). So, we choose a Machine Learning model $g$ and train (or fit) it on the train set (calibrate its internal parameters) so that $g(x)$ looks similar to $y$ for $\{x,y\}$ in the train set. We quantify "look similar" by introducing a function to minimise called Error Measure. Thus, $g$ is our approximation of $f$ and $g(x)$ for $x$ in the test set (called Prediction) is our guess of $y$ for the test set as asked.
  

 - Error measure

  There are different error measures (also called Loss/Cost/Objective Functions), but here we use the most common one - Root Mean Square Error (RMSE), for a model $g$:
$$ RMSE(g) = \sqrt{ \frac{1}{n} \sum_{i=1..n}(y_i - g(x_i))^2 } $$

```{r}
RMSE <- function(y, g)
  return(sqrt(mean( (y-g)**2 )))
```


 - Overfitting

  Almost always the data we have is not a pure reflection of a law of nature but also of some noises (it is why it is hard to find $g \equiv f$) and if we consider a model too complicated for the problem, it can also fit the noise, as on the figure below. A model that is too simple is not a good choice neither. In order to find a suitable model from a set of models, we need to test models on data that was not used in the training. For this purpose we divide the train set into two parts (80% and 20%), then we train each model on 80% data and compare its predictions over the 20% data with the real labels. It gives a RMSE per model, and a model with the smallest RMSE is the winner.
  
```{r pressure, echo=FALSE, fig.cap="Overfitting", out.width = '100%'}
knitr::include_graphics("images/overfit.png")
```
  
  
 - MovieLens
 
  In the current project, we consider the MovieLens 10M database, it consists of movies and users ratings and we want to be able to say which rating a specific user would give to a specific movie (in order to know what to propose to watch to this user). It consists of 10 million of ratings (10 M rows), for each rating we have a user ID, a time when the rating was given and a movie ID. Each movie has a title (equivalent to movie ID) with the year of production, an and a set of genres (a movie can have multiple genres).


  
  
# Preprocessing
  
```{r message=FALSE, warning=FALSE}
# List of packages we need
list_of_packages <- list("randomForest",
                         "kableExtra",
                         "tidyverse",
                         "lubridate",
                         "corrplot",
                         "ggplot2",
                         "readxl",
                         "dslabs",
                         "knitr",
                         "mlr")

# Function that loads and installs if necessary indicated packages
UsePackages = function(list_of_packages) {
  for (p in list_of_packages){
    # if (!is.element(p, installed.packages()[,1]))
    #   install.packages(p)
    require(p, character.only = TRUE)
  }
}
UsePackages(list_of_packages)

# precision
prec <- 3

# data frame to stock results
results <- tibble()
```




# Create test and validation sets

Create edx set (train set) and validation set (test and validatiob set in the same time)

```{r message=FALSE, warning=FALSE}
# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip


# Avoid downloading data we already have
if (file.exists("ml-10M100K/ratings.dat") & file.exists("ml-10M100K/movies.dat")){
  
  ratings <- read.table(text = gsub("::", "\t", readLines("ml-10M100K/ratings.dat")),
                        col.names = c("userId", "movieId", "rating", "timestamp"))
  movies <- str_split_fixed(readLines("ml-10M100K/movies.dat"), "\\::", 3)
  
}else{
  
  dl <- tempfile()
  download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)
  ratings <- read.table(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                        col.names = c("userId", "movieId", "rating", "timestamp"))
  movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
  
}

# Treat data
colnames(movies) <- c("movieId", "title", "genres")
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
                                           title = as.character(title),
                                           genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")


# Validation set will be 10% of MovieLens data
set.seed(1)
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]


# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")


# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)

# change the format from 'data.frame' to 'tibble'. And blend the rows
edx <- as_tibble(edx)[sample(1:nrow(edx)),]
validation <- as_tibble(validation)[sample(1:nrow(validation)),]
```


# Feature Selection and Feature Engineering

Feature Selection means that we remove irrelevant variables that only add noise.

Feature Engineering means that we add new variables.


## Year of production and year of rating

```{r}
# extract year from the title and remove title
edx <- edx %>%
  extract(title, "year", regex="\\(([0-9 \\-]*)\\)$") %>% mutate(year=as.integer(year))
validation <- validation %>%
  extract(title, "year", regex="\\(([0-9 \\-]*)\\)$") %>% mutate(year=as.integer(year))

# timestamp to year of the publication of rating
edx <- edx %>%
  mutate(timestamp = as.integer(year(as_datetime(timestamp))))
validation <- validation %>%
  mutate(timestamp = as.integer(year(as_datetime(timestamp))))
```

Add mean/median rating per year

```{r}
df_years <- edx %>% group_by(year) %>% 
  summarise(mean_per_year=mean(rating), median_per_year=median(rating))
edx <- edx %>% left_join(df_years, by="year")
```



## Genres

```{r}
# data frame of genres and its numbers
(df_genres <- edx %>%
  separate_rows(genres, sep = "\\|") %>%
  group_by(genres) %>%
  summarise(number = n(), mean_rating = mean(rating)) %>%
  arrange(desc(number)))
```

Divide 'genres' into separate genres

```{r}
#' create a data.frame with dummy genres columns from a list of mixed genres
GetDummyGenres <- function(my_vector, my_genres){
  df2 <- sapply(my_vector,
                function(x){
                  zeros <- rep(0,length(my_genres))
                  x <- strsplit(x, "\\|")[[1]] # split by char "|" into two strings
                  zeros[match(x, my_genres)] <- 1
                  return(as.integer(zeros))
                }, 
                USE.NAMES=FALSE) %>% t
  colnames(df2) <- my_genres
  df2 <- df2 %>% as_tibble # %>% select(-`(no genres listed)`)# %>% mutate_all(as.factor)
  return(df2)
}

# movies and its genres
df_movies <- edx %>% group_by(movieId) %>%
  summarise("mean_per_movie"=mean(rating), 
            "median_per_movie"=median(rating), 
            "number"=n(),
            "genres" = genres[1])
df_movies <- df_movies %>% bind_cols(GetDummyGenres(.$genres, df_genres$genres))
```


A movie can have multiple genres, so can estimate its rating as average of average ratings per genres

```{r}
(df_movies <- df_movies %>% 
  mutate(mean_per_genre =
           rowSums(as.matrix(df_movies %>% select(df_genres$genres)) * df_genres$mean_rating) /
           rowSums(df_movies %>% select(df_genres$genres))) %>% 
   select(mean_per_genre, names(df_movies)))

edx <- edx %>% left_join(df_movies %>% select(movieId, mean_per_genre), by="movieId")
```



## Add mean/median rating per movie

```{r}
edx <- edx %>% 
  left_join(df_movies %>% select(movieId, mean_per_movie, median_per_movie), by="movieId")
```

## Add mean/median rating per user

```{r}
df_users <- edx %>% group_by(userId) %>% summarise("mean_per_user"=mean(rating),
                                                   "median_per_user"=median(rating),
                                                   "number"=n())
edx <- edx %>% left_join(df_users %>% select(-number), by="userId")
```






# Data Summary and Data Visualisation

```{r}
# summary
print(summary(edx))
# check if there are NA in data
cat("Number of rows containing NA :", edx %>% filter(!complete.cases(.)) %>% nrow, "\n")

cat("Number of users  :", nrow(df_users), "\n")
cat("Number of movies :", nrow(df_movies), "\n")

# plot a Histogram of Ratings
ggplot(edx, aes(rating)) + 
  geom_histogram(binwidth=0.5, fill=I("blue"), col=I("red"), alpha=I(.2)) +
  ggtitle("Histogram of Ratings") + 
  scale_x_continuous(breaks=seq(0,5,.5))

# plot Mean Rating per Genre
ggplot(df_genres) + ggtitle("Mean Rating per Genre") + xlab(NULL) + ylab("Rating") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  geom_point(aes(genres, mean_rating, size=number), col="tomato")
cat("We clearly see that the number of movies produced per year increases with time while the mean rating per year decreases\n")


# plot Mean Rating per Year and Timestamp
ggplot() + 
  geom_point(data = edx %>% group_by(year) %>% summarise(mean_rating = mean(rating), number=n()),
            aes(year, mean_rating, col="year", size=number)) + 
  geom_point(data = edx %>% group_by(timestamp) %>% summarise(mean_rating = mean(rating), number=n()),
            aes(timestamp, mean_rating, col="timestamp", size=number)) + 
  ggtitle("Mean Rating per Year and Timestamp") + xlab(NULL) + ylab("Rating")

# plot correlations
corrplot(cor(edx %>% select(-c(genres, movieId, userId))), type="upper", diag=FALSE, title="Correlation Matirx")
cat("We see that the rating is quite correlated with mean per user and mean per movie which are in their turn are highly correlated to its medians\n")

# edx is too big to plot it all, so the next analysis is done over a small part of edx
edx_short <- edx[1:1000,]

# plot ratings vs other variables
ggplot(edx_short) + geom_point(aes(rating, genres), col="#FF9999")
ggplot(edx_short) + geom_point(aes(rating, movieId), col="#56B4E9")
cat("we can see that some ratings are less frequant for some generes\n")

# plot histrograms
# df <- gather(edx_short %>% select(-c("genres", "timestamp")))
df <- gather(edx_short %>% select(userId, movieId, timestamp, year))
ggplot(df, aes(value, fill=key)) + 
  facet_wrap(~key, scales="free", ncol=1) +
  geom_histogram(bins=60)
cat("We see that our data is not homogeneous\n")

# Conclusion
cat("We do not see any obvious pattern that would certainly help us to determine a rating\n")
```


## Feature Importance

```{r}
model_RandomForest <- randomForest(rating ~ ., 
                                   data = edx[1:1e5,] %>%
                                     select(-c(userId, movieId, genres, contains("median"))),
                                   ntree=10, keep.forest=FALSE, importance=TRUE)
varImpPlot(model_RandomForest)
```





# Model 0: Mean/Median Rating

```{r}
# get mean and median and calculate rmse
rating_mean   <- mean(edx$rating)
rating_median <- median(edx$rating)
cat("Mean Rating:  ", round(rating_mean, prec),"\n")
cat("Median Rating:", round(rating_median, prec),"\n")

results_temp <- tibble("Model" = c("mean", "median"),
                       "RMSE"  = c(RMSE(validation$rating, rating_mean),
                                   RMSE(validation$rating, rating_median)))
# add it to results base
results <- results %>% bind_rows(results_temp)
# show results table in latex format
kable(results_temp, "latex", booktabs = TRUE) %>% kable_styling(latex_options = "striped")
```


# Model 1: Mean/Median Rating per User

```{r}
cat(min(df_users$number), max(df_users$number), "\n")
q_90 <- quantile(df_users$number, 0.9)
hist(df_users %>% filter(number<q_90) %>% .$number, breaks = 30)

# prediction
validation <- validation %>% left_join(df_users %>% select(-number), by="userId")

# get rmse and stock it
results_temp <- tibble("Model" = c("mean_per_user", "median_per_user"), 
                       "RMSE"  = c(RMSE(validation$rating, validation$mean_per_user),
                                   RMSE(validation$rating, validation$median_per_user)))
results <- results %>% bind_rows(results_temp)
# show results table in latex format
kable(results_temp, "latex", booktabs = TRUE) %>% kable_styling(latex_options = "striped")
```




# Model 2: Mean/Median Rating per Movie

```{r}
cat(min(df_movies$number), max(df_movies$number), "\n")
q_90 <- quantile(df_movies$number, 0.9)
hist(df_movies %>% filter(number<q_90) %>% .$number, breaks = 30)

# prediction
validation <- validation %>% 
  left_join(df_movies %>% select(movieId, mean_per_movie, median_per_movie), by="movieId")

# get rmse and stock it
results_temp <- tibble("Model" = c("mean_per_movie", "median_per_movie"),
                       "RMSE"  = c(RMSE(validation$rating, validation$mean_per_movie),
                                   RMSE(validation$rating, validation$median_per_movie)))
results <- results %>% bind_rows(results_temp)
# show results table in latex format
kable(results_temp, "latex", booktabs = TRUE) %>% kable_styling(latex_options = "striped")
```




# Model 3 Mean/Median Rating per Year

```{r}
# prediction
validation <- validation %>% left_join(df_years, by="year")

# get rmse and stock it
results_temp <- tibble("Model" = c("mean_per_year", "median_per_year"), 
                       "RMSE"  = c(RMSE(validation$rating, validation$mean_per_year),
                                   RMSE(validation$rating, validation$median_per_year)))
results <- results %>% bind_rows(results_temp)
# show results table in latex format
kable(results_temp, "latex", booktabs = TRUE) %>% kable_styling(latex_options = "striped")
```


# Model 4 Mean Rating per Genre

```{r}
# prediction
validation <- validation %>% left_join(df_movies %>% select(movieId, mean_per_genre), by="movieId")

# get rmse and stock it
results_temp <- tibble("Model" = "mean_per_genre", 
                       "RMSE"  = RMSE(validation$rating, validation$mean_per_genre))
results <- results %>% bind_rows(results_temp)
# show results table in latex format
kable(results_temp, "latex", booktabs = TRUE) %>% kable_styling(latex_options = "striped")
```



# Model 5 Ordinary Least Squares regression (OLS)

```{r}
# data for regression type train
edx2 <- edx %>% select(-c(userId, movieId, genres, contains("median")))
```

```{r}
ols <- lm(rating ~ ., data = edx2)
summary(ols)
# test
results_temp <- tibble("Model" = "ols",
                       "RMSE"  = RMSE(validation$rating, predict(ols, validation)))
results <- results %>% bind_rows(results_temp)
# show results table in latex format
kable(results_temp, "latex", booktabs = TRUE) %>% kable_styling(latex_options = "striped")
```


# Model 6 Movie Effect Model


$$y_i = \mu + b_{movie(i)} + \epsilon_i$$


```{r}
Movie_Effect_Model <- function(lambda, return_prediction=FALSE){
  # the average rating
  mu <- mean(edx$rating)
  
  # calculate b_movie coefficients
  movie_effect <- edx %>% 
    group_by(movieId) %>% 
    summarize(b_m = sum(rating - mu) / (n() + lambda))

  # add to validation
  validation <- validation %>% left_join(movie_effect, by='movieId')
  
  # rmse
  my_rmse <- RMSE(validation$rating, (mu + validation$b_m))
  
  if (return_prediction){
    return(list("rmse"       = my_rmse,
                "prediction" = mu + validation$b_m))
  }else{
    return(my_rmse)
  }
}

# calculate errors for a set of lambda values and choose the smallest rmse
lambdas <- seq(0, 10, 0.25)
model_rmses <- sapply(lambdas, Movie_Effect_Model)
lambda_of_smallest_rmse <- lambdas[which.min(model_rmses)]

# plot it
ggplot() + geom_line(aes(lambdas, model_rmses), col="#56B4E9", size=1) +
  geom_vline(xintercept=lambda_of_smallest_rmse, col="red") + ggtitle("Movie Effect Model: RMSE as function of lambda parameter") + ylab("RMSE") + xlab("lambda")

# add the best prediction
results_temp <- tibble("Model" = "movie_effect",
                       "RMSE"  = model_rmses[which.min(model_rmses)])
results <- results %>% bind_rows(results_temp)
# show results table in latex format
kable(results_temp, "latex", booktabs = TRUE) %>% kable_styling(latex_options = "striped")
```




# Model 7 Movie User Effect Model


$$y_i = \mu + b_{movie(i)} + b_{user(i)} + \epsilon_i$$


```{r}
Movie_User_Effect_Model <- function(lambda, return_prediction=FALSE){
  # the average rating
  mu <- mean(edx$rating)
  
  # calculate b_movie coefficients
  movie_effect <- edx %>% 
    group_by(movieId) %>% 
    summarize(b_m = sum(rating - mu) / (n() + lambda))
  
  # calculate b_user coefficients
  movie_user_effect <- edx %>% 
    left_join(movie_effect, by="movieId") %>% 
    group_by(userId) %>% 
    summarize(b_u = sum(rating - mu - b_m) / (n() + lambda))

  # add to validation
  validation <- validation %>% 
    left_join(movie_effect, by='movieId') %>% 
    left_join(movie_user_effect, by='userId')
  
  # rmse
  my_rmse <- RMSE(validation$rating, (mu + validation$b_m + validation$b_u))
  
  if (return_prediction){
    return(list("rmse"       = my_rmse,
                "prediction" = mu + validation$b_m + validation$b_u))
  }else{
    return(my_rmse)
  }
}

# calculate errors for a set of lambda values and choose the smallest rmse
lambdas <- seq(0, 10, 0.25)
model_rmses <- sapply(lambdas, Movie_User_Effect_Model)
lambda_of_smallest_rmse <- lambdas[which.min(model_rmses)]

# plot it
ggplot() + geom_line(aes(lambdas, model_rmses), col="#56B4E9", size=1) +
  geom_vline(xintercept=lambda_of_smallest_rmse, col="red") + ggtitle("Movie Effect Model: RMSE as function of lambda parameter") + ylab("RMSE") + xlab("lambda")

# add the best prediction
results_temp <- tibble("Model" = "movie_user_effect",
                       "RMSE"  = model_rmses[which.min(model_rmses)])
results <- results %>% bind_rows(results_temp)
# show results table in latex format
kable(results_temp, "latex", booktabs = TRUE) %>% kable_styling(latex_options = "striped")
```



# Conclusion

The model that has the smallest RMSE is the Movie User Effect model

```{r}
kable(results, "latex", booktabs = TRUE) %>% kable_styling(latex_options = "striped")
```

Predicted ratings

```{r}
submission <- validation %>% select(userId, movieId, rating) %>% 
  mutate("prediction" = 
           Movie_User_Effect_Model(lambda_of_smallest_rmse, return_prediction=TRUE)$prediction)
# write on the disk
write_csv(submission, "submission.csv")
```



